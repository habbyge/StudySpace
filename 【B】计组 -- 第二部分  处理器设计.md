## 【B】计组 -- 第二部分：处理器设计

### 建立数据通路 ：指令+运算 = CPU

#### 指令周期（Instruction Cycle）

​		计算机每执行一条指令的过程，可以分解成几个步骤：

1. **Fetch（取得指令）**

   从PC寄存器里找到对应的指令地址，根据指令地址从内存里把具体的指令加载到指令寄存器中，然后把PC寄存器自增。

2. **Decode（指令译码）**

   根据指令寄存器里面的指令，解析成要执行什么样的操作，是R，I，J的哪一种指令，具体要操作哪些寄存器、数据或内存地址。

3. **Execute（执行指令）**

   实际运行指令，进行算术逻辑操作、数据传输、或者直接的地址跳转。

4. 重复1~3步骤

![img](.\images\1840bead02cfbe5d8f70e2f0a7b962a7.jpg)

在取指令阶段，指令是放在存储器里的；通过PC寄存器和指令寄存器取出指令的过程、以及指令解码过程是由控制器（Control Unit）操作的。执行指令阶段，无论是算术操作、逻辑操作的R指令，还是进行数据传输、条件分支的I型指令，都是由算术逻辑单元，也就是运算器处理。

这样对于一条指令的 “Fetch - Decode - Execute”的循环，我们把这个循环称之为**指令周期**（Instruction Cycle）

与主频相关是**时钟周期**。

从内存里读取一条指令最短时间，成为**机器周期/CPU周期**

指令周期与 时钟周期、机器周期的关系：

![img](.\images\1a7d2d6cf7cb78a8f48775268f452e48.jpeg)







#### 组成CPU的4种硬件电路

​		它们分别是，ALU 这样的组合逻辑电路、用来存储数据的锁存器和 D 触发器电路、用来实现 PC 寄存器的计数器电路，以及用来解码和寻址的译码器电路。





#### 时钟信号的硬件实现

​		我们通过反馈电路，创建了时钟信号，然后再利用这个时钟信号和门电路组合，实现了“状态记忆”的功能。终于可以把数据“存储”下来了。

​		CPU在空闲状态就会停止执行，具体来说就是切断时钟信号，CPU的主频就会瞬间降低为0，功耗也会瞬间降低为0。由于这个空闲状态是十分短暂的，所以你在任务管理器里面也只会看到CPU频率下降，不会看到降低为0。当CPU从空闲状态中恢复时，就会接通时钟信号，这样CPU频率就会上升。所以你会在任务管理器里面看到CPU的频率起伏变化。

#### PC 寄存器所需要的计数器

​		我们常说的PC寄存器，还有个名字叫**程序计数器**。



#### 建立数据通路，构造一个最简单的 CPU

![img](.\images\6863e10fc635791878d1ecd57618b871.jpeg)



### 面向流水线的指令设计

#### CPU 的流水线设计

​		CPU 的指令执行过程，其实也是由各个电路模块组成的。我们在取指令的时候，需要一个译码器把数据从内存里面取出来，写入到寄存器中；在指令译码的时候，我们需要另外一个译码器，把指令解析成对应的控制信号、内存地址和数据；到了指令执行的时候，我们需要的则是一个完成计算工作的 ALU。这些都是一个一个独立的组合逻辑电路，我们可以把它们看作一个团队里面的产品经理、后端工程师和客户端工程师，共同协作来完成任务。

​		如果我们把一个指令拆分成“取指令 - 指令译码 - 执行指令”这样三个部分，那这就是一个三级的流水线。如果我们进一步把“执行指令拆分成**“取指令（IF）- 指令译码（ID）- 指令执行（EX）- 内存访问（MEM）- 数据写回（WB） ”**，那么它就会变成一个五级的流水线。

> 流水线执行示意图

![img](E:\personal\study\blogs\images\1e880fa8b1eab511583267e68f0541ad.jpeg)

​		这样一来，我们就不用把时钟周期设置成整条指令执行的时间，而是拆分成完成这样的一个一个小步骤需要的时间。同时，每一个阶段的电路在完成对应的任务之后，也不需要等待整个指令执行完成，而是可以直接执行下一条指令的对应阶段。就是**指令流水线**。

​		为了能够不浪费 CPU 的性能，我们通过把指令的执行过程，切分成一个一个流水线级，**流水线技术并不能缩短单条指令的响应时间这个性能指标，但是可以增加在运行很多条指令时候的吞吐率**。

​		但是一味地增加流水线深度，并不能无限地提高性能。同样地，因为指令的执行不再是顺序地一条条执行，而是在上一条执行到一半的时候，下一条就已经启动了，所以也给我们的程序带来了很多挑战。



### 冒险和预测

​		流水线设计需要解决的三大冒险，分别是**结构冒险**（Structural Hazard）、**数据冒险**（Data Hazard）以及**控制冒险**（Control Hazard）。



#### 结构冒险：为什么工程师都喜欢用机械键盘？

> 同一个时钟周期，两个不同指令访问同一个资源

![img](.\images\c2a4c0340cb835350ea954cdc520704e.jpeg)

​	CPU 的结构冒险里面。对于访问内存数据和取指令的冲突，现代CPU的解决方案就是在高速缓存层面拆分成**指令缓存**和**数据缓存**

​	内存的访问速度远比 CPU 的速度要慢，所以现代的 CPU 并不会直接读取主内存。它会从主内存把指令和数据加载到高速缓存中，这样后续的访问都是访问高速缓存。而指令缓存和数据缓存的拆分，使得我们的 CPU 在进行数据访问和取指令的时候，不会再发生资源冲突的问题了。

![img](.\images\e7508cb409d398380753b292b6df8391.jpeg)



#### 数据冒险：三种不同的依赖关系

​	数据冒险，其实就是同时在执行的多个指令之间，有数据依赖的情况。这些数据依赖，我们可以分成三大类，分别是**先写后读**（Read After Write，RAW）、**先读后写**（Write After Read，WAR）和**写后再写**（Write After Write，WAW）。



##### 先写后读（Read After Write）

```c
int main() {
  int a = 1;
  int b = 2;
  a = a + 2;
  b = a + 3;
}
```

这段代码简单地定义两个变量 a 和 b，然后计算 a = a + 2。再根据计算出来的结果，计算 b = a + 3。

```assembly

int main() {
   0:   55                      push   rbp
   1:   48 89 e5                mov    rbp,rsp
  int a = 1;
   4:   c7 45 fc 01 00 00 00    mov    DWORD PTR [rbp-0x4],0x1
  int b = 2;
   b:   c7 45 f8 02 00 00 00    mov    DWORD PTR [rbp-0x8],0x2
  a = a + 2;
  12:   83 45 fc 02             add    DWORD PTR [rbp-0x4],0x2
  b = a + 3;
  16:   8b 45 fc                mov    eax,DWORD PTR [rbp-0x4]
  19:   83 c0 03                add    eax,0x3
  1c:   89 45 f8                mov    DWORD PTR [rbp-0x8],eax
}
  1f:   5d                      pop    rbp
  20:   c3                      ret  
```



​	我们需要保证，在内存地址为 16 的指令读取 rbp-0x4 里面的值之前，内存地址 12 的指令写入到 rbp-0x4 的操作必须完成。这就是先写后读所面临的数据依赖。如果这个顺序保证不了，我们的程序就会出错

​	这个先写后读的依赖关系，我们一般被称之为**数据依赖**，也就是 Data Dependency。



##### 先读后写（Write After Read）

​		先读后写的依赖，一般被叫作**反依赖**，也就是 Anti-Dependency。



##### **写后再写（Write After Write）**

​		这个写后再写的依赖，一般被叫作**输出依赖**，也就是 Output Dependency。





#### 再等等：通过流水线停顿解决数据冒险

​		最简单的一个办法，不过也是最笨的一个办法，就是**流水线停顿**（Pipeline Stall）。

​		如果我们发现了后面执行的指令，会对前面执行的指令有数据层面的依赖关系，那最简单的办法就是“再等等”。我们在**进行指令译码的时候，会拿到对应指令所需要访问的寄存器和内存地址**。**如果判断会触发数据冒险，就让整个流水线停顿一个或者多个周期。**

​		时钟信号会不停地在 0 和 1 之前自动切换。其实，我们并没有办法真的停顿下来。流水线的每一个操作步骤必须要干点儿事情。所以，在实践过程中，**我们并不是让流水线停下来，而是在执行后面的操作步骤前面，插入一个 NOP 操作**，也就是执行一个其实什么都不干的操作。



#### NOP 操作和指令对齐

回忆下五级流水线“取指令（IF）- 指令译码（ID）- 指令执行（EX）- 内存访问（MEM）- 数据写回（WB） ”



在实践当中，各个指令不需要的阶段，并不会直接跳过，而是会运行一次 NOP 操作。通过插入一个 NOP 操作，我们可以使后一条指令的每一个 Stage，一定不和前一条指令的同 Stage 在一个时钟周期执行。这样，就不会发生先后两个指令，在同一时钟周期竞争相同的资源，产生结构冒险了。但是这样却也运行了两次空转的NOP操作。

![img](.\images\94dda2330b07c08530540ae11838c569.jpeg)





那针对流水线冒险的问题，计算机组成原理中有一个更加精巧的解决方案，**操作数前推**。

![img](.\images\dceadd35c334974d8270052b37d48c27.jpeg)

操作数前推的解决方案，比流水线停顿更进了一步。流水线停顿的方案，有点儿像游泳比赛的接力方式。下一名运动员，需要在前一个运动员游玩了全程之后，触碰到了游泳池壁才能出发。而操作数前推，就好像短跑接力赛。后一个运动员可以提前抢跑，而前一个运动员会多跑一段主动把交接棒传递给他。





#### 填上空闲的 NOP：上菜的顺序不必是点菜的顺序

无论是流水线停顿，还是操作数前推，归根到底，只要前面指令的特定阶段还没有执行完成，后面的指令就会被“阻塞”住。

但是这个“阻塞”很多时候是没有必要的。尽管你的代码生成的指令是顺序的，但是如果后面的指令不需要依赖前面指令的执行结果，完全可以不必等待前面的指令运算完成。

样的解决方案，在计算机组成里面，被称为**乱序执行**（Out-of-Order Execution，OoOE）



#### CPU 里的“线程池”：理解乱序执行



![img](.\images\153f8d5e4a4363399133e1d7d9052804.jpeg)



1. 在取指令和指令译码的时候，乱序执行的CPU和其他使用流水线架构的CPU一样。会一级一级顺序地进行取指令和指令译码的工作。

2. 在指令译码完之后。CPU不会直接进行指令执行，而是进行一次指令分发，把指令发到一个叫**保留站**（Reservation Stations）的地方。

3. 这些指令不会立即执行，而是会等到他们所依赖的数据传递给他们之后，才会交到后面的功能单元（Function Unit）其实就是ALU去执行。

4. 指令执行的阶段完成之后，并不能立刻把结果写回到寄存器里面去，而是把结果再存放到一个叫**重排序缓冲区**（Re-Order Buffer）的地方。

5. 在重排序缓冲区里，CPU会按照取指令的顺序，对指令的计算结果重新排序。只有排在前面的指令都已经完成了，才会提交指令，完成整个指令的运算结果。

6. 实际的指令运算结果数据，并不是直接写到内存或者高速缓存里，而是先写入存储缓冲区（Store Buffer），最终才会写入高速缓存和内存里。

   

可见只有 CPU 内部指令的执行层面，可能是“乱序”的。在最终指令的计算结果写入到寄存器和内存之前，依然会进行一次排序，以确保所有指令在外部看来仍然是有序完成的。

```c
a = b + c
d = a * e
x = y * z
```

里面的 d 依赖于 a 的计算结果，不会在 a 的计算完成之前执行。但是我们的 CPU 并不会闲着，因为 x = y * z 的指令同样会被分发到保留站里。因为 x 所依赖的 y 和 z 的数据是准备好的， 这里的乘法运算不会等待计算 d，而会先去计算 x 的值。如果我们只有一个 FU 能够计算乘法，那么这个 FU 并不会因为 d 要等待 a 的计算结果，而被闲置，而是会先被拿去计算 x。





#### 分支预测：今天下雨了，明天还会继续下雨么？

​	在结构冒险和数据冒险中，你会发现，所有的流水线停顿操作都要从指令执行阶段开始。流水线的前两个阶段，也就是取指令（IF）和指令译码（ID）的阶段，是不需要停顿的。CPU 会在流水线里面直接去取下一条指令，然后进行译码。取指令和指令译码不会需要遇到任何停顿，这是基于一个假设。这个假设就是，所有的指令代码都是顺序加载执行的。不过这个假设，在执行的代码中，一旦遇到 if…else 这样的条件分支，或者 for/while 循环，就会不成立。

​	这个时候，我们就引入了一个新的解决方案，叫作**分支预测**（Branch Prediction）技术，也就是说，让我们的 CPU 来猜一猜，条件跳转后执行的指令，应该是哪一条。

​	**动态分支预测。**用一个比特，去记录当前分支的比较情况，直接用当前分支的比较情况，来预测下一次分支时候的比较情况。称为一级分支预测或1比特饱和计数。优化方案引入一个状态机：

![img](.\images\ea82f279b48c10ad95027c91ed62ab5d.jpeg)



​	这个状态机里，我们一共有 4 个状态，所以我们需要 2 个比特来记录对应的状态。这样这整个策略，就可以叫作 **2 比特饱和计数**，或者叫**双模态预测器**（Bimodal Predictor）。









### GPU 

对于图像进行实时渲染的过程，可以被分解成下面这样 5 个步骤：

1. 顶点处理（Vertex Processing）
2. 图元处理（Primitive Processing）
3. 栅格化（Rasterization）
4. 片段处理（Fragment Processing）
5. 像素操作（Pixel Operations）





我们可以把 GPU 做一次小小的瘦身，只留下取指令、指令译码、ALU 以及执行这些计算需要的寄存器和缓存就好了。一般来说，我们会把这些电路抽象成三个部分，就是下面图里的取指令和指令译码、ALU 和执行上下文。

![img](.\images\4c153ac45915fbf3985d24b092894b9d.jpeg)



​	GPU 里面的多核、多 ALU，加上多 Context，使得它的并行能力极强。同样架构的 GPU，如果光是做数值计算的话，算力在同样价格的 CPU 的十倍以上。而这个强大计算能力，以及“统一着色器架构”，使得 GPU 非常适合进行深度学习的计算模式，也就是海量计算，容易并行，并且没有太多的控制分支逻辑。




















