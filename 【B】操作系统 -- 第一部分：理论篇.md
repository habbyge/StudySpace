## 【B】操作系统 -- 第一部分：理论篇

### 操作系统原理知识大纲

- #### 进程管理

  - 进程概念
  - 进程通信
  - 线程与多线程模型
  - 处理机调度与死锁
    - 进程调度
    - 死锁及死锁的处理
    - 银行家算法
    - 处理机调度

- #### 内存管理

  - 内存管理
    - 页式存储
    - 段式存储和段页式存储
  - 虚拟存储技术
    - 页面置换算法

  

- #### 文件管理

  - 文件系统概述







### 一、进程管理

![image-20201014104455120](.\images\b_os_part1_001.png)



#### 进程的概念

##### **进程的概念**

$$
进程控制块(PCB)+程序+数据=进程实体
$$



进程是程序的一次执行。是程序及其数据在处理机上顺序执行时所发生的**活动**。

进程实体存在的意义是，操作系统为了管理程序的运行，需要这样一个进行资源分配和调度的一个独立单位。

每个进程都配置一个PCB对其进行描述。从结构上看，进程实体是由程序段，数据段和进程控制块三部分组成。



##### **进程的状态与转换**

五种基本状态 ：（就绪、执行、阻塞）+ （创建、终止）

七种状态机 ：（就绪、执行、阻塞）+ （创建、终止）+（挂起、激活）

1. 创建状态

   首先，由进程申请一个空白PCB，并向PCB中填写用于控制和管理进程的信息；

   然后，为该进程分配运行时所必须的资源；

   最后，把该进程转入就绪状态并插入就绪队列之中。

2. 就绪状态

   当进程已经分配到除CPU以外的所有必要的资源，只要获得处理机便可以立即执行。

3. 执行状态

   当进程已经获得处理机，其程序正在处理机上执行。

4. 阻塞状态

   正在执行的进程，由于等待某个事件发生而无法执行时便放弃处理机而处于阻塞状态。例如：等待I/O完成、申请缓冲区不能满足、等待信号等。

5. 终止状态

   首先，等待操作系统善后处理。即当一个进程到达自然结束点，或是被其他有终止权的进程终结，它将进入终止状态。

   最后，将其PCB清零，并将PCB空间返还系统。

   

   ![image-20201014113713040](.\images\image-20201014113713040.png)

   

   **挂起和激活**

   ![image-20201014144438985](.\images\image-20201014144438985.png)

   | 状态变化               | 描述                                                         |
   | ---------------------- | ------------------------------------------------------------ |
   | 活动就绪   =》静止就绪 | 由于内存紧张或是系统优化性能的需要 ，将某些暂时不需要运行的进程暂时换出外存 |
   | 活动阻塞 =》 静止阻塞  | 操作系统根据当前资源状况和性能要求所导致挂起的变化。或活动就绪队列为空，需要挂起一个活动阻塞以便腾出内存空间，从外存中激活一个静止就绪进程 |
   | 静止就绪 =》活动就绪   | 1. 外存上的静止就绪进程具有更高的优先级                      2. 内存中已经有了一大块空闲的空间                                  3. 当前内存中没有活动就绪进程 |
   | 静止阻塞 =》活动阻塞   | 1. 操作系统已经得知导致该进程阻塞的事件即将结束       2. 内存中已经有了一大块空闲空间 |
   | 静止阻塞=》静止就绪    | 当在外存上的静止阻塞进程所需资源得到满足，或者等待事件已经完成时，会引起该状态变化 |
   | 执行态 =》静止就绪     | 运行进程出现了错误或者异常，或需要分析进程                   |

   *活动转静止态，总是为了暂时腾出内存空间

   *静止转活动态，总要满足内存中有一大块空闲空间的条件

   

   > 第二部分会继续研究Linux系统进程状态及转换

   ![image-20201014144624198](.\images\image-20201014144624198.png)

   

   



#### **进程的控制**

- **进程控制块 -- PCB**

在操作系统中，为每个进程专门定义了一个数据结构 -- 进程控制块PCB（Process Control Block）。作为进程实体的一部分，记录了操作系统所需的，用于描述进程的当前情况以及管理进程运行的全部信息，是操作系统中最重要的记录型数据结构。



**PCB存在的意义是：**

1. 作为独立运行基本单位的标志
2. 能实现间断性运行方式
3. 提供进程管理所需要的信息
4. 提供进程调度所需要的信息
5. 实现与其他进程的同步与通信


$$
进程控制块(PCB)+程序+数据=进程实体
$$


![image-20201014145940253](.\images\image-20201014145940253.png)



![image-20201014150116923](.\images\image-20201014150116923.png)



| 名称           | 描述                                                         |
| -------------- | ------------------------------------------------------------ |
| 进程标识符     | 用于唯一地标识一个进程。通常分为外部标识符、内部标识符两种   |
| 处理机状态信息 | 也成为处理机的上下文，主要由处理机的各种寄存器中的内容组成      *  通用寄存器GC：可被用户程序访问、用于暂存信息                            *  指令寄存器PC：存放要访问的下一条指令的地址                                    *  程序状态字PSW：含有条件码、执行方式、中断屏蔽标志等状态信息。    *用户栈指针 |
| 进程调度信息   | 在操作系统进行调度时，必须了解进程的状态及有关进程调度的信息：        *  进程状态  *进程优先级  *进程调度所需其他信息 （进程已等待CPU的时间总和、进程已执行的时间总和等） *事件（阻塞原因） |
| 进程控制信息   | *程序和数据的地址 *进程同步和通信机制（实现进程同步和进程通信的必须机制，如消息队列指针、信号量等） *资源清单（运行所需以及已经分配到该进程的资源清单） *链接指针（它给出了本进程PCB所在队列中的下一个进程的PCB的首地址） |
| 其他信息       |                                                              |



**常见进程控制块组织方式 ：**

**链接的方式**

![image-20201014152046360](.\images\image-20201014152046360.png)

**索引的方式**

![image-20201014152410673](.\images\image-20201014152410673.png)



执行指针指向当前运行的进程的PCB的首地址 









- **进程控制**

操作系统内核基本操作：

中断处理：CPU每执行完一条指令，都要判断中断引脚是否有信号传来。

时钟管理：时间片用完，产生中断信号

原语操作：系统状态下执行的某些具有特定功能的程序。



1. 创建原语
2. 撤消原语
3. 阻塞与唤醒原语
4. 挂起与激活原语

原语是原子操作，不可拆分，操作系统中通常封装成一个个函数来实现原语。



操作系统中的进程不是单独存在的，进程以家族（进程树）形式存在：

![image-20201014154258154](.\images\image-20201014154258154.png)



这里只看进程控制 -- 撤销原语的实现 ，即终止一个进程的过程：

![image-20201014154611054](.\images\image-20201014154611054.png)

步骤归纳：

1. 读取进程状态

2. 修改进程调度标志

3. 结束子孙进程

   递归进程家族（进程树）

4. 归还资源

5. 移除队列











#### 进程通信 IPC

​	因为每个进程拥有的内存地址空间相互独立，安全起见，一个进程不能直接访问另外一个进程的内存地址空间。	

​	理论上，实现进程间通信有三种形式：

##### 1. 共享空间

概述：	

​	设置一个共享空间，进程通过互斥地访问共享空间，进行通信。

两种方式：

- ​	基于数据结构的共享

​			生产者消费者问题

- ​	基于存储区的共享

​			

##### 2. 管道通信

概述：

​	设置一个特殊的共享文件（又名pipe文件），具体为操作系统会在内存中开辟一个大小固定的缓冲区，按照管道地规则进行通信。

步骤:

​	写进程（发送进程）以字符流形式将大量数据送人管道

​	读进程（接收进程），则从管道中接收（读取）数据

管道地规则：

​	i.  一条管道只能实现半双工通信（单向），实现双向同时通信需要两条管道

​	ii. 各进程要互斥地访问管道

​	iii. 写满时，不能再写（写进程进入睡眠，等待读进程读取后唤醒），读空时，不能再读（读进程进入睡眠，等待写进程写入后唤醒）。

​	iv. 没写满，不能读；没读空，不能写；





##### 3. 消息传递

概述：

​	进程通信内容以格式化的消息（Message）为单位。消息头+消息体的形式。进程间通过操作系统提供的“发送/接收消息”原语进行通信。

两种方式：

​	直接通信方式 -- 消息直接挂到接收方进程消息队列里。

​		 进程A把消息存到缓冲区，链接到进程B的PCB的message queue。进程B 找到并拷贝一份消息到自己的内存空间。

​	间接通信方式 -- 消息先发送到中间体（信箱），等待进程取用



​	

> Linux 操作系统中 实现的进程间通信方式：
>
> 信号
>
> 管道 -- 匿名管道、命名管道 
>
> 内存共享+信号量
>
> 消息队列
>
> socket













#### 进程同步与互斥

临界资源

临界区：访问临界资源的那部分程序



对共享数据的并发访问可能导致数据的不一致性（脏读现象），要保证数据一致性，就需要一种*保证并发进程正确执行顺序*（进程同步）的机制，这种机制就是进程互斥机制。

> 进程互斥机制，保证访问临界资源的进程同步执行



进程互斥实现方法：

​	软件实现方法 -- 在程序中通过变量来作为进入临界区的标识

​			单标识法、双标识先检查法、双标识后检查法、Peterson算法

​			分别违背了违背**空闲让进、忙则等待、有限等待、让权等待**原则。

​	硬件实现方法 -- 

- 中断屏蔽方法：只适合操作系统内核进程，不适合用户进程，不适用多处理机。

- Test-and-Set简称TS指令或TSL指令：

  把上锁和检查操作用硬件的方式变成了原子操作。

  缺点是：违背让权等待原则，暂时无法进入临界区的进程会占用CPU并循环执行TSL指令，导致忙等。

  

- Swap指令

  在x86种称为XCHG指令。适用于多处理机

  缺点同样是是：违背让权等待原则，暂时无法进入临界区的进程会占用CPU并循环执行TSL指令，导致忙等。

  



#### 信号量机制

​	更好的解决进程同步互斥问题的机制是信号量机制。其中记录型信号量通过定义一个信号量结构体记录资源数，避免忙等。

- ​	**整数型信号量**

​		可用资源数 S ，它仅能通过两个标准原子操作wait(S)、signal(S) 来访问，这两个操作俗称P、V操作。

​		进入临界区 P一下，先检查后减1，退出临界区V一下。

​		![image-20201015112105885](.\images\image-20201015112105885.png)



- **记录型信号量**

  采取了“让权等待" 的策略，避免了忙等。

  除了一个代表资源数目的整数变量value外，还增加一个进程链表指针list，用于链接所有等待进程：

  ```c
  /*信号量结构体*/
  typedef struct{
      int value;	//资源数量
      struct process * list;	//等待队列
  } Semaphore；
  ```

  ```c
  //wait()即P() 相当于申请资源
  void wait(Semaphore s){
      //资源数量减去1
      s.value--;
      //如果资源 <0 说明无可用资源
      if(s.value<0){
          //将该进程放入该资源等待队列
          add this_process to s.list;
          //阻塞该进程
          block(this_process);
      }
  }
  ```

  

  ```c
  //signal() 即V() 相当于释放资源
  void signal(Semaphore s){
      //资源数量加1
      s.value++;
      //如果资源数<=0说明等待队列有进程
      remove a process P from s.list;
      //唤醒该进程
      wakeup(P);
  }
  ```

  

- **AND型信号量与信号量集**

  需要多种资源，并且所有资源齐备才能执行。

  这就需要一次性把所有所需资源，全部分配给



##### 经典同步问题 -- **生产者消费者问题**

​	 · 大小固定的缓冲区

​	 · 缓冲区为空时，消费者不能再进行消费

​	·  缓冲区为满时，生产者不能再进行生产



伪代码：

```c
samephore mutex  = 1; //互斥信号量，实现对缓冲区的互斥访问
semaohore empty = n; //资源型信号量，表示空闲缓冲区的数量
smephore full = 0; //资源型信号量，表示产品的数量，即当前产品库存

//生产者
producer(){
    while(true){
        生产一个产品;
        P(empty);	//消耗一个空位
        P(mutex);
        把产品放入缓冲区;
        V(mutex);
        V(full);	//增加一个产品
    }
}

//消费者
consumer(){
    while(true){
        P(full); //消耗一个产品;
        P(mutex);
        从缓冲区取出一个产品;
        V(mutex);
        V(empty);//增加一个空位
        使用产品;
    }
}
```



> 把生产者的P(empty)和P(mutex)调换位置、消费者P(full)和P(mutex)调换位置会发生什么？

缓冲区满后，empty=0，full=n。生产者P(mutex)、P(empty) 后，进入睡眠，等待消费者从缓冲区取走产品后，唤醒生产者。消费者先执行到P(mutex) 由于mutex信号量未被生产者释放，所以陷入等待，自然也不会执行V(empty) 释放empty信号量。两者循环等待被对方唤醒，出现“死锁”



##### 经典同步问题 -- **读-写者问题**

读者和写者共享一个内存区/文件。当一个写者访问时，排斥其他写者和读者；而允许多个读者同时访问；且仅当无人访问这个存储区/文件时，写者才能访问。

```c
int count = 0; //读者数量
semaphore mutex_rw = 1; //读写锁信号量，用于实现对共享文件的互斥访问
semaphore mutex_reader_count = 1; //保证对读者数量count互斥访问--“count变量访问锁”

//写者
writer(){
    while(1){
        P(mutex_rw);//对互斥信号量P操作（读写锁）
        写文件/内存区域;
        V(mutex_rw);//对互斥信号量V操作(释放读写锁)
    }
}

//读者
reader(){
    while(1){
       P(mutex_reader_count); //各读进程互斥访问count
       	 if(count == 0)		//第一个读进程读之前需要对mutex_rw加锁
            P(mutex_rw);	//对mutex_rw读写锁加锁
       	 count++;			//读进程数+1
       V(mutex_reader_count);//“count变量访问锁”解锁
        
       读文件/内存区域;
       
       P(mutex_reader_count);
         count--;	//读完，读进程数-1
         if(count == 0)
             V(mutex_rw);//如果是最后一个读者，退出前要释放“读写锁”
       V(mutex_reader_count);//读者数更新完毕，释放“count变量访问锁”
    }
}
```

这种实现法为“读进程优先”，只要有进程还在读，写进程就要一直阻塞等待，可能"饿死“。

可以加一个fair信号量实现”读写公平法“



##### 经典同步问题 -- 哲学家就餐问题

​	依次拿起左、右两边的筷子，才能吃饭，否则等待筷子。

![image-20201016152630171](.\images\image-20201016152630171.png)

```c
//定义信号量数组chopstick[5]，并初始化
semaphore chopstick[5] = {1,1,1,1,1};
//i号哲学家的进程
Pi(){
    do{
        P(chopstick[i]);//左边筷子
        P(chopstick[(i+1)%5]);//取右边筷子
        	eat;
        V(chopstick[i]);//放回左边筷子
        V(chopstick[(i+1)%5]);//返回右边筷子
        think;
    }while(1);
}
```



当五个哲学家都想要进餐，分别拿起左边筷子的时候，就出现了”死锁“。



信号量解决哲学家就餐问题几种策略：

1. 设置一个取筷子的信号量

2. 至多允许4个哲学家同时进餐

3. 仅当一个哲学家左右两边筷子都可用时才允许他抓起筷子

4. 对哲学家顺序编号，要求奇数号哲学家先抓左边筷子，偶数哲学家反之。

   

```c
//定义信号量数组chopstick[5]，并初始化
semaphore chopstick[5] = {1,1,1,1,1};
semaphore mutex=1;	//设置取筷子的互斥信号量
//i号哲学家的进程
Pi(){
    do{
        P(mutex);	//加锁
        P(chopstick[i]);//左边筷子
        P(chopstick[(i+1)%5]);//取右边筷子
        V(mutex);	//释放锁
        	eat;
        V(chopstick[i]);//放回左边筷子
        V(chopstick[(i+1)%5]);//返回右边筷子
        think;
    }while(1);
}
```



























#### 线程

​	线程是更小的、更轻量级且能够独立运行的基本单位。

​	线程之间可以并发运行且共享相同（进程的）的地址空间。



​	从前有一户老张家，一家三口，其乐融融。村里给老张家分了一块地，穷人的孩子早当家，大儿子拿起工具去地里播种、施肥、种玉米。后来有了二儿子，拿着他的工具，也在这块上，但是他种起了大豆。



​	线程并不是创建越多越好，跟据核数，CPU密集型业务创建 N+1、IO密集型业务 2N+1



































#### 系统调度（处理机调度)

系统调度性能指标：周转时间、平均周转时间、带权周转时间、平均带权周转时间、等待时间



![image-20201016160123371](.\images\image-20201016160123371.png)



##### 作业调度 

- **调度算法  -  FCFS（先来先服务）**



- **调度算法 -- SJF（短作业优先）/ SPF（短进程优先）**

追求最少的平均等待时间



- **调度算法 -- HRRN（高响应比优先）**

综合考虑作业/进程的等待时间和**要求服务**的时间。

选取响应比高的作业/进程进行调度。

![image-20201016160801476](.\images\image-20201016160801476.png)

当要求服务时间相同时，退化成FCFS。

当等待时间相同时，退化成SJF。





##### 进程调度

- **调度算法 -- RR时间片轮转** **（\*Round Robin, RR\*）**

- 最高优先级调度算法

  两个类别：

  静态优先级算法：优先级创建进程之初即确定，运行时不改变

  动态优先级：根据进程动态变化调整进程优先级

  两种处理方式：

  非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程

  抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程

  

  缺点可能会导致低优先级的进程永远不会运行。

  

- **多级反馈队列** 机制 --  RR时间片轮转算法 + 最高优先级调度算法

  [多级] 设置了 多个就绪队列，每个队列优先级从高到低，优先级越高时间片越少。

  [反馈] 表示如果有新的进程加入，将其放入第一级队列的末尾，如果第一级规定的时间片内没能运行完成，则将其移入第二级队列末尾（下次会获得更多时间片）。当高优先级的队列为空，才调度低优先级的队列中的进程。

  ![image-20201016163039417](.\images\image-20201016163039417.png)



​	可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也会更长了，所以该算法很好的**兼顾了长短作业，同时有较好的响应时间。**





#### 死锁

​	多个进程争夺同类资源且资源分配顺序不当，产生了相互等待，无外力作用无法继续执行的状态



一个死锁的示例程序：

```java
public static void main(String[] args) {
    final Object a = new Object();
    final Object b = new Object();
    Thread threadA = new Thread(new Runnable() {
        public void run() {
            synchronized (a) {
                try {
                    System.out.println("now i in threadA-locka");
                    Thread.sleep(1000l);
                    synchronized (b) {
                        System.out.println("now i in threadA-lockb");
                    }
                } catch (Exception e) {
                    // ignore
                }
            }
        }
    });

    Thread threadB = new Thread(new Runnable() {
        public void run() {
            synchronized (b) {
                try {
                    System.out.println("now i in threadB-lockb");
                    Thread.sleep(1000l);
                    synchronized (a) {
                        System.out.println("now i in threadB-locka");
                    }
                } catch (Exception e) {
                    // ignore
                }
            }
        }
    });

    threadA.start();
    threadB.start();
}

```



死锁检测工具：Jstack 、JConsole



> ##### 死锁产生的必要条件？
>

1. 互斥条件

   资源访问互斥

2. 不剥夺条件

   进程已经至少保持了一个资源，且不能被其他进程强行夺走

3. 请求和保持条件

   请求新的，得不到就阻塞，但对自己已获得的资源保持不放

4. 循环等待条件

   出现循环等待链

   

> ##### 如何避免死锁？

​	如同银行家放贷之前要调查你的贷款额度、目前是否有贷款信用如何等等，来规避风险。

​	在资源分配过程之前先计算资源分配的安全性，防止系统进入不安全状态（不安全状态即指系统可能进入死锁状态）。

​	

**银行家算法避免死锁：**

![image-20201016183227360](.\images\image-20201016183227360.png)



**安全性检测算法**

​	查找安全序列(可能有多个)

![image-20201016183352570](.\images\image-20201016183352570.png)



分配资源前，遍历进程列表，看看哪个进程的Need 矩阵能与目前的Work矩阵（初始值为Available）匹配，匹配到则将其目前的资源 -- Allocation矩阵 ，”模拟“交还给Work矩阵，并将其状态置为Finish = true。最终判断是否所有的进程都能Finish = true。





直观地理解银行家算法：

![image-20201016183950795](.\images\image-20201016183950795.png)













### 二、内存管理

![image-20201017123245370](.\images\image-20201017123245370.png)



#### 内存管理

​		内存管理主要是内存的分配与回收，另外，内存管理机制负责将逻辑地址与物理地址转换。

​		简单分为**连续分配管理方式**和**非连续分配管理方式**这两种。连续分配管理方式是指为一个用户程序分配一个连续的内存空间，常见的如 **块式管理** 。同样地，非连续分配管理方式允许一个程序使用的内存分布在离散或者说不相邻的内存中，常见的如**页式管理** 和 **段式管理**。



##### 连续分配管理方式

- ​	**固定分区分配**

​		 **块式管理**，采用固定分块。内存碎片，内存利用率不高。运行了一段时间后，它的内存空间将会被分割成许多小的分区，而缺乏大的空闲空间。交换技术（Swapping）虽然能解决，但是其花费大量CPU时间。

- ​	**动态分区分配**

​		经典算法是**伙伴系统**。其内存分配与回收原理，可概括为 ”二分“与”合并“  -- 

​	![image-20201016221144422](.\images\image-20201016221144422.png)

​	分裂开的两个相同大小的空间即为”伙伴“，组成一个链表。



##### 分页式存储管理

​	程序的地址空间（逻辑地址/虚拟地址）被分成大小为2k的片段，称为page ，**页面**或虚页。

​	**逻辑地址结构为：低位--页内地址（偏移量）+ 高位--页号** ，页面大小决定低位所占多少位，比如16位系统，页面大小1k，即2的10次方,则低10位表示页内地址，高6位用来表示页号

![image-20201016225212365](.\images\image-20201016225212365.png)





​	物理内存也被分成大小相等的片，成为frame，**页框**、实页或物理块。
$$
 页面大小 = 页框大小
$$
​	**页表**结构 -- 系统为每个进程建立上边存储了物理块号，即建立了页面与页框的映射关系，保证根据页号正确找到物理内存中物理块号。页表存储在内存物理块中。

​	有多少个页表项（PTE）代表多少个页面。



​	

![image-20201016224352827](.\images\image-20201016224352827.png)

###### **地址映射**

​	地址映射是由CPU中的硬件 MMU（内存管理单元，Memory Manage Unit）完成的。

​	![image-20201016230117412](.\images\image-20201016230117412.png)

*页号如果大于页表长度，会触发越界中断*





###### **快表**

​	**局部性原理**

​	例如数组的遍历访问，呈现出以下两种局部性特征：

- 时间局部性

  被引用过一次的存储器位置在未来会被多次引用（通常在循环中）。

- 空间局部性

  如果一个存储器的位置被引用，那么将来他附近的位置也会被引用。



由于页表存储在内存，访问效率低，基于局部性原理，人们用硬件TLB（联想存储器、缓冲存储器）来缓存正在运行的进程当前用到的页号和对应的块号，成为快表。（可以理解为对页表的部分缓存）。先访问缓冲存储器中的快表，没有的话再访问内存中的页表。





###### 二级页表与多级页表

页表在内存空间连续存放，需要占用很多个连续的页框（物理块），页表每个项代表一个页面和物理块的对应关系，但其实是没有必要让整个页表常驻内存，因为进程在一段时间内只需要访问某几个特定的页面。

将页表离散分配到内存，在寄存器中建立一张**页目录表**即可。（该寄存器叫页目录寄存器）。

所以就有了如下32位二级页表地址结构：

![image-20201017115219849](.\images\image-20201017115219849.png)



事实上，32位机器采用两级页表结构，64位机器采用四级页表结构。



##### 分段式存储管理

页式存储有两个问题：

1.  将物理内存分为大小相同的一个个”页“，不可避免的产生**页内**碎片
2. 逻辑上相连的代码，可能会被分到不同的页框中



段式存储的思想是，你只要告诉我 ”**从哪开始切、切多长的内存给你**" 

![image-20201017121310073](.\images\image-20201017121310073.png)











##### 段页式存储管理

”先分段、再把段分页“

地址结构 == 段号 + 段内页号 + 页内偏移 

![image-20201017121915785](.\images\image-20201017121915785.png)











##### **内存扩充技术**

- Swapping （对换、交换）技术

- 覆盖技术

​		多个程序的某些部分共享一个存储空间

- 虚拟内存技术



#### 虚拟存储技术

​	主内存大小是极其有限的（4G、8G、16G），操作系统定义了一个连续的虚拟地址空间，并且把内存扩展到硬盘空间。

![image-20201017125322392](.\images\image-20201017125322392.png)

我们的程序只是部分装载入内存的，在载入程序的时候，只需要将程序的一部分装入内存，而将其他部分留在外存，然后程序就可以执行了；

1. **缺页中断**：如果**需执行的指令或访问的数据尚未在内存**（称为缺页或缺段），则由处理器通知操作系统将相应的页面或段**调入到内存**，然后继续执行程序；

   

##### **页面置换算法**

​	地址映射过程中，若在页面中发现所要访问的页面不在内存中，则发生缺页中断 ，如果当前内存中没有空闲的页面，操作系统就必须在内存选择一个页面将其移出内存，这种选择淘汰哪一个页面的规则叫作页面置换算法。

- **OPT置换算法（最佳置换算法）**

  理论上的算法，它是要淘汰未来（很长时间内）不再使用的页面。

- **FIFO置换算法（先进先出置换算法）**

  淘汰内存中呆的最久的页面。算法不合理，呆的最久不等于最少被使用

  

- **LRU（Least Recently Used）置换算法（最近最少使用置换算法）**

  根据页面调入内存后的使用情况，淘汰掉***最近时间内最少使用***的页面。

  ~ LRU 链表实现：

  ​	维护一个链表，最近刚使用的作为首节点，每次访问内存，找到相应页号，把它从链表中摘下来插到链表之首。这样保证链表末尾就是要淘汰的页面。

  ~ LRU 用栈实现：

  ​	利用一个栈保存当前调入内存的各个页面的页面号，当需要淘汰内存中的一个页面的时候，把栈底的页面号对应的页面淘汰，把调入主内存的页面号入栈到栈顶。类似乒乓球桶，把球倒到另一个桶，取出一个球，再倒回去，然后再放入一个新的球。

  ​	

- **LFU （Least Frequently Used）**

  当一个缺页中断发生时，选择访问次数最少的那个页面，并淘汰之。

  与LRU算法相对。LFU算法只考察页面被访问频次，不在乎时间。

  

- **Clock置换算法（时钟置换算法）**

  LRU的问题是每次内存访问，访问到某一页时都要做一次查找，看看是否在链表或者堆栈中。

  时钟置换算法思想用到了页表当中的访问位，装入内存时将其初始化为0 ， 页面被访问到则置为1。将页面组织成循环链表（类似钟表盘），指针指向最老的页面（最先进来的页面），当发生缺页中断时，指针指向的”最老“页面的访问位若为0则淘汰，若为1，则重置为0，然后指针下移，直到找到被淘汰页面。



​		**时钟算法问题和改进**：时钟算法问题和改进：综合利用到访问位A和修改位M

​			一个问题是，被修改过的页面换出内存要比未修改过的页面换出内存开销大。所以，考虑到置换代价，改进始终算法综合利用到访问位A和修改位M ，进行多一次扫描，争取优先置换掉”未访问且未被修改“的页面，而不是直接就淘汰”最老未被访问“的页面：

![image-20201017141457231](.\images\image-20201017141457231.png)

​	

​	第一次扫描：优先寻找修改位和访问位都为0 ，但该次不改变访问位A。

​	第二次扫描：若第一次未找到,则继续扫描,找A=0 M=1,这次将扫描过的A置为0。
























